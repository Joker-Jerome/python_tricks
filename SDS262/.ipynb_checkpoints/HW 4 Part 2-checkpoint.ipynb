{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: PCA\n",
    "In class we discussed how PCA can be used as a dimensionality reduction technique as well as latent factor discovery technique. In both cases we used PCA to visualize. Below, we will explore two other applications of PCA, compression and regularization.\n",
    "\n",
    "I highly recommend that you read the documentation for `np.linalg.svd` before starting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netid = \"xxx\"\n",
    "name = \"xxx yyy\"\n",
    "print netid\n",
    "print name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The following lines import the modules we will use.\n",
    "Do not import any others</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import misc, ndimage\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressing an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to load an image so that we can compress it. This is a way to compress an iamge, but it is not that great, but a lot of other ideas are fundamentally based on this actual principle. You should place the yalelogo.jpeg photo in the same directory as your ipython notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=misc.imread(\"./yalelogo.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image starts out as a 3-D numpy array. This is because we effectively have an image for each color channel for R, G, and B. As in class, we will average out these pixel intensities. We will also threshold to obtain a purely black and white image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ab=(np.mean(A,2)<100)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Ab,cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem A:\n",
    "The matrix `Ab` is a matrix of 1s and 0s. Plot the singular values of the pictures and compute the best rank $2$ approximation of the matrix and display the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem B:\n",
    "In the above we did not remove the means. Now, for each *row* compute the mean of the row and subtract that number from each of the rows. In math, if we let $M$ be our $d_1 \\times d_2$ image matrix we want to compute\n",
    "$$\n",
    "M - M 1_{d_2} 1_{d_2}^T/d_2\n",
    "$$\n",
    "where again $1_{d_2}$ is the all ones *column* vector of length $d_2$. Note, above is slightly different than what happened in class with the TOY example where we removed another mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem C:\n",
    "Now that we have removed the mean. Let's again plot the singular values of the shifted image and recompute the best rank $2$ approximation. Plot the picture by adding back the mean. Do you notice any qualitative differences between the images or the new plots of the singular values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your brief explanation of the qualitative differences here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization of MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem A: Load the MNIST data\n",
    "Load the MNIST dataset including the images and labels. This will involve you finding the appropriate data again. You can use the previous assignment. Should should have a `labels` array that is `60000x1` and an `mnist` 2-D array that is `60000x(28*28)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "with gzip.open('train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_images = f.read()\n",
    "\n",
    "with gzip.open('train-labels-idx1-ubyte.gz','rb') as f:\n",
    "    train_labels = f.read()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=np.array(bytearray(train_labels[8:]))\n",
    "A=np.array(bytearray(train_images[16:]))\n",
    "A=A.reshape(60000,28*28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem B: Separate the data into 0s and 8s\n",
    "Now, we will separate the data into $0$ and $8$ values. You should be left with $11774$ images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I=np.logical_or(labels==0,labels==8)\n",
    "mnist=A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## you need to find an appropriate choice for I to subselect the appropriate examples\n",
    "mnist = mnist[I,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem C: Compute the average image.\n",
    "Plot a picture of the average image. That is, compute the mean over all images, and then use `plt.imshow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu=np.mean(mnist,axis=0)\n",
    "\n",
    "plt.imshow(mu.reshape(28,28),cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem D: Subtract the average image from all of the examples\n",
    "Use broadcasting to subtract the average image from all of the examples. Same the average image as `mu` and save the new matrix as `mnist_centered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_centered=mnist-mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert np.all(np.isclose(np.sum(mnist_centered,axis=0),0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem E: Perform pca and visualize the points on the 2-D V-space (head-tilt space)\n",
    "Plot the points on the 2-D V-space found by projecting your data onto the top two principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-16f1db83d682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_centered\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_matrices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlowd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmnist_centered\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlowd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlowd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "U,S,V=np.linalg.svd(mnist_centered,full_matrices=0)\n",
    "\n",
    "lowd=mnist_centered.dot(V[:2,:].T)\n",
    "\n",
    "plt.plot(lowd[labels[I]==8,0],lowd[labels[I]==8,1],'r.')\n",
    "plt.plot(lowd[labels[I]==0,0],lowd[labels[I]==0,1],'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with PCA.\n",
    "\n",
    "A common technique in practice is to actually use PCA to reduce the computational complexity of the linear regression problem as well as improve the statistical performance. The method couples the idea of dimensionality reduction and regularization. Let's generate a dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(int((hashlib.md5('snn7')).hexdigest(),16) % 200000)\n",
    "n=1000\n",
    "d=700\n",
    "ustar=np.random.normal(0,1,(1,d))\n",
    "A=np.random.normal(0,1,(n,1)).dot(ustar) + np.random.normal(0,.1,(n,d))\n",
    "xstar=ustar.T\n",
    "b=A.dot(xstar)+np.random.normal(0,1,(n,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In class we saw how to project the data down to a $2$-dimensional space. Now we want to see how to do that more generally. In order to do so we provide some extra background.\n",
    "\n",
    "## SVD Expansion\n",
    "Recall that the SVD of a matrix $M \\in \\mathbb{R}^{d_1 \\times d_2}$ is\n",
    "$$\n",
    "M = U S V^T\n",
    "$$\n",
    "where $U$ and $V$ are orthogonal matrices and $S$ is a diagonal matrix. The columns of $U$ are denoted the left singular vectors and the columns of $V$ are denoted that right singular vectors. Let $u_i = U[:,i]$ and $v_i = V[:,i]$. The elements $S[i,i]$ are the singular values of the matrix $M$. Let's let $R = S V^T$ (We are using $R$ for right). Then,\n",
    "$$\n",
    "M[:,i] = \\sum_{j=1}^{d_1} u_j R[j,i]\n",
    "$$\n",
    "In words, the $i^{th}$ column of $M$ is some linear combination of the orthogonal vectors $u_j$. Specifically, they are weighted by $R[j,i]$. Thus, $R[j,i]$ is denoted as the coordinate of column $i$ with respect to $u_j$. Furthermore, because the $u_j$ are orthogonal we can think of the coordinates as belonging to an orthogonal system. The use of this is that we can plot, for example, $R[1,:]$ on the $y$-axis and $R[0,:]$ on the $x$-axis as we did in class.\n",
    "### How do we find $R$?\n",
    "In order to find $R$ we can apply the orthogonality of $U$. From above, $M = U R$. Recall that $U^T U = I$. Therefore,\n",
    "$$\n",
    "R = U^T M\n",
    "$$\n",
    "From that, we can simply extract the different rows of $R$ to obtain the coordinates for each of the different singular vectors $u_j$. Now, since we sorted the diagonal entries of $S$ in decreasing order, the rows capture the information of the matrix $M$ in decreasing order as well.\n",
    "\n",
    "*Everything we just did with respect to columns carries over with the rows as well*\n",
    "\n",
    "## Where does linear regression fit?\n",
    "\n",
    "In linear regressin we have a matrix $A \\in \\mathbb{R}^{n \\times d}$ where we take $n$ to be the number of examples and $d$ is the number of features that each example has. We also have an outcomes $b \\in \\mathbb{R}^n$. The common way of solving linear regression that we have focused on is ordinary least squares (OLS) where we solve\n",
    "$$\n",
    "\\hat{x} \\in \\arg \\min_{x} \\|A x -b \\|_2^2\n",
    "$$\n",
    "Sometimes, the matrix $A$ might be well approximated by some low-rank matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem D:\n",
    "Find the rank $2$ matrix $\\hat{A}_2$ such that\n",
    "$$\n",
    "\\|\\hat{A}_2 - A\\|_F^2 = \\sum_{i,j} (\\hat{A}_2[i,j] - A[i,j])^2\n",
    "$$\n",
    "is minimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u,s,v=np.linalg.svd(A,full_matrices=False)\n",
    "##add extra code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem E:\n",
    "Now more generally write a python function that computes the best rank $r$ matrix $\\hat{A}_r$ such that\n",
    "$$\n",
    "\\|\\hat{A}_r - A\\|_F^2 = \\sum_{i,j} (\\hat{A}[i,j] - A[i,j])^2\n",
    "$$\n",
    "is minimized over all rank $r$ matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bestrankr(A,r):\n",
    "    return np.zeros((A.shape[0],A.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.isclose(np.linalg.norm(Ahat_2-bestrankr(A,2)),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem F:\n",
    "We want to find a closed form solution of \n",
    "$$\n",
    "x_{k} \\in \\arg \\min_x \\|\\hat{A}_k x - b\\|_2^2\n",
    "$$\n",
    "In this case you will not be able to use `np.linalg.solve` because you will get a matrix is singular warning. Instead, use the singular value decomposition. As a hint, recall that the optimality conditions state\n",
    "$$\n",
    "\\hat{A}_k^T \\hat{A}_k x_k = \\hat{A}_k^T b\n",
    "$$\n",
    "We can't invert the matrix on the left. However, we can use that fact that if $A = U S V^T$ is the singular value decomposition, then $U^T U = I$. Algorithmically, gradient descent will still work in this setting.\n",
    "\n",
    "Write your solution with respect to the matrices $U$, $S$, and $V$. Also write a function to compute the solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your solution here:\n",
    "    $$\n",
    "x = 0 \\times U \\times V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computerankleastsquares(A,b,k):\n",
    "    return np.zeros((A.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem G:\n",
    "Now, using cross-validation from the part 1, compute the optimal $k$ for minimizing the error. You cannot use the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let\n",
    "$$\n",
    "V_k = \\left ( v_1 v_2 ... v_k \\right )\n",
    "$$\n",
    "be the $d \\times k$ matrix of just the first $k$ columns of the matrix $V$ of right singular vectors of the matrix $A$. Again, please read the numpy documentation for `np.linalg.svd` because of how it outputs the matrix $V$.\n",
    "\n",
    "Let's generate a new test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Atest=np.random.normal(0,1,(n,1)).dot(ustar) + np.random.normal(0,.1,(n,d))\n",
    "btest=Atest.dot(xstar)+np.random.normal(0,1,(n,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now on the test set, compare the test error between  $\\|A_{test} \\hat{x} - b_{test}\\|_2^2$, $\\|A_{test} x_k - b_{test}\\|_2^2$, $\\|A_{test} V_k V_k^T \\hat{x} - b_{test}\\|_2^2$, and $\\|A_{test} V_k V_k^T x_k - b_{test}\\|_2^2$. Can you explain the differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem H (Bonus):\n",
    "Can you find any connections between ridge regression from the previous problem and low-rank regularized linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type your solution here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10db6f210>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEGCAYAAACZ0MnKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHCpJREFUeJzt3XmYVNWd//H3F1qQRRSCoAHBtQ2oqKAdhYjF2myCRESD\nEDGY4J44Tn6akPxAYzJqxiSuyRjUaFyQuCEqAkaKEVGREEAIAs4gKLKpICiojX3mj1NtN003VnfX\n7XOr6vN6nvv0re3eb52n6S9nN+ccIiIi6WgQOgAREckeShoiIpI2JQ0REUmbkoaIiKRNSUNERNKm\npCEiImkLnjTM7F4z22RmSzN0vRlmttXMnqn0/OVmttrMvjSzVpm4l4hIvgmeNID7geIMXu8WYHQV\nz88D+gBrM3gvEZG8EjxpOOfmAVsrPmdmR6ZqDG+Y2VwzK6zB9eYAn1Tx/BLn3DrA6hy0iEieKggd\nQDXuAcY75/7HzIqAP+JrCSIiElDskoaZNQO6A38zs7JawX6p14YDNwAV1z4x4D3n3MB6DVREJA/F\nLmngm8y2Oue6Vn7BOfcU8FQdr6/FtkREaimyPo0ajoqy1IFzbgewxsxGVLhWl5renur7Lvb1moiI\n7EOUHeFpjYoys0eA+UChma0zs4uAC4BxZrbYzJYBQ9O9qZn9N/AY0Dt1vX6p5680s3eBdsASM7un\n5l9JRCS/WZRLo5tZR2C6c66mNQUREYmh4ENuRUQkeyhpiIhI2oKOnjIzjWQSEakF51yQAT1R1zS+\ndqSSc06Hc0ycODF4DHE5VBYqC5XFvo+QohxyW9WoKBERyWKRNU8550ZFdW0REQlDHeExkUgkQocQ\nGyqLciqLciqLeIh0nsbX3tzMhW6fExHJNmaGy9GOcBERySFKGiIikjYlDRERSZuShoiIpE1JQ0RE\n0qakISIiaVPSEBGRtClpiIhI2pQ0REQkbUoaIiKSNiUNERFJm5KGiIikTUlDRETSpqQhIiJpU9IQ\nEZG0KWmIiEjalDRERCRtShoiIpI2JQ0REUmbkoaIiKRNSUNERNKmpCEiImlT0hARkbQpaYiISNqU\nNEREJG1KGiIikrbIkoaZDTCzt8xslZldG9V9RESk/phzLvMXNWsArAL6AO8DbwDnO+feqvQ+F8X9\nRURymZnhnLMQ946qplEErHbOrXXOlQBTgGER3UtEROpJVEmjHfBuhcfvpZ4TEZEsVhA6gLPPhoYN\noaDA/6x4vv/+0LTpnkeTJuXnLVpAy5blxwEHgAWpsImI5IeoksZ6oEOFx+1Tz+2lceNJOAdffglH\nH53g2GMTfPkl7N4Nn38OO3f644MPys937oRPP4Xt22HbNti61R+7dsGBB5YnkYMPhrZt4ZBD/FF2\nXvbzoIOUZEQk/pLJJMlkMnQYQHQd4Q2BlfiO8A3AAuB7zrkVld6X0Y7wkhKfRMoSyZYtsHEjbNrk\nf1Y+LymBDh2gY0d/lJ2X/WzXDvbbL2PhiYhkRMiO8EiSBvght8Bt+H6Te51zN1XxnqCjp3bsgHXr\nYO3avX+uXQubN/sEUlgIxxyz58/DDoMGmuUiIgHkZNJI6+YxH3L7+eewZg2sWgWrV/ufZecffQRH\nHQXHH++PE07wPw8/XMlERKKlpJGFPvnEJ5Dly+HNN2HZMn9s3QqdO/sE0qULdO0KJ58MzZuHjlhE\ncoWSRg7Zts0nkmXLYOlS+Mc/fFLp0AG6dSs/Tj7Zj/YSEakpJY0cV1ICK1bAwoU+iZQlko4doXt3\nf5x+Ohx7rJq2ROTrKWnkoZISnzhefRXmz/c/t23zyaMskRQVQbNmoSMVkbhR0hAANmzYM4ksWeL7\nRXr1gkQCevTwkxpFJL8paUiVdu70yWPOHEgmYfFiOOkkn0R69fK1kiZNQkcpIvVNSUPS8umnvhYy\nZ44/li3zzVjFxTBgAHTqpBnuIvlASUNq5eOP4e9/h5kz4YUXoLTUJ4/iYujb1y+TIiK5R0lD6sw5\nWLmyPIHMmwcnnghDh8KwYX5klojkBiUNybhdu3w/yDPP+KN5c588hg71fSENG4aOUERqS0lDIuUc\nLFoE06b5BLJ+PQwZ4hNIcbFGZIlkGyUNqVfvvAPTp8PTT/uJhgMHwrnn+p8ajSUSf0oaEszmzfDU\nUzB1qk8ggwb5BDJggBKISFwpaUgsbN4MTz7pE8iiRTB4MIwc6WsgjRqFjk5EyihpSOxs2uQTyKOP\n+nWzzj0XxoyB007TXBCR0JQ0JNbeeQceegj++lc/F2TMGBg9Go48MnRkIvlJSUOygnPwxhs+eTz2\nmN/BcMwY34TVsmXo6ETyh5KGZJ2SEj+J8K9/hVmz4Kyz4OKLoWdPNV+JRE1JQ7Lahx/65PHnP/tk\ncvHFcOGF0LZt6MhEcpOShuQE5+C112DyZN+J3ru3TyD9+2sGukgmKWlIztm+HaZM8Qlk40a45BKf\nQNq0CR2ZSPYLmTS0uahEokUL+NGPYMECv3zJ//6vXzRxzBh4/XVfKxGR7KOahtSbjz6C+++Hu++G\nVq3g8svhvPM081ykptQ8JXmltNSPvLrzTli4EC66CC69FA4/PHRkItlBzVOSVxo08GtcPf+834lw\n92445RRf61iwIHR0IrIvqmlILOzYAffdB3/4A7RvD9dc4+d+aNSVyN7UPCWSsnu3X3X31lv9/I+f\n/ATGjoVmzUJHJhIfShoilTjnm65uvRVeftmPxLrqKk0YFAH1aYjsxQx69PCTBOfPh23boFMnuOIK\nWLs2dHQi+SvjScPMRpjZMjP70sy6Zvr6kn+OOQbuussv0d68OXTt6kdcvfVW6MhE8k8UNY03geHA\n3AiuLXmsbVu46SZ4+22/LHvPnn6fj3/+M3RkIvkj40nDObfSObca0FqnEomWLeGXv/SzzLt3hyFD\n/BDeV14JHZlI7lOfhmSt5s3h6qt98jj7bL8xVP/+8OqroSMTyV0FtfmQmc0GKo5jMcABE5xz02ty\nrUmTJn11nkgkSCQStQlJ8ljjxn501dix8MADcP750LkzXH89FBWFjk6k7pLJJMlkMnQYQIRDbs1s\nDnCNc27RPt6jIbeScV984ScK/uY30KWLTx7duoWOSiRzcnnIrfo1pN41auSXYl+9GgYOhGHD/KEO\nc5G6i2LI7dlm9i5wGvCsmc3I9D1E0tG4sV9J9+23oU8fGDwYRoyAlStDRyaSvTQjXPLGzp1wxx3w\nn/8Jw4fDxInQrl3oqERqLpebp0Rio2lTuPZaWLXKD9vt0sU/3ro1dGQi2UNJQ/JOy5Zw882wZIlP\nGIWF/vGuXaEjE4k/JQ3JW+3bwz33+AUR33jDL1cyeTJ8+WXoyETiS30aIikLFsBPf+prH7feCv36\nhY5IpGpaGl0kJpyDadN88igshN/+1k8UFIkTdYSLxISZX5Jk+XJf00gk/LDdLVtCRyYSD0oaIlVo\n1MjvGrhiBey3n69t/Pa38PnnoSMTCUtJQ2QfvvENv2/5K6/4o1MnePxx34wlko/UpyFSA3PmwI9/\nDG3awO23q79DwlCfhkiW6NULFi3ya1mdeSb827/Bxx+Hjkqk/ihpiNRQQQFceaXvLN++3TdZPfAA\nlJaGjkwkemqeEqmjBQvgiit8MrnzTr+HuUiU1DwlksWKiuC112DcOL/t7Pjx8OGHoaMSiYaShkgG\nNGjgk8aKFX647nHHwYMPapSV5B41T4lEYOFCX+M48ED44x/h2GNDRyS5RM1TIjnmlFPg9df9KKse\nPWDSJPjss9BRidSdkoZIRAoK/JyOxYth6VK/f8dLL4WOSqRu1DwlUk+mT/ejrHr29KvotmkTOiLJ\nVmqeEskDZ53l53Yccggcfzzce686yiX7qKYhEsCSJXDxxb6j/J574MgjQ0ck2UQ1DZE8c+KJ8Oqr\nUFzs53ncdpt2DJTsoJqGSGCrVvlax+7dvsmqU6fQEUncqaYhkscKCyGZhNGj4Ywz4Ne/hpKS0FGJ\nVE01DZEYWbvWTwrctAnuuw9OPjl0RBJHqmmICAAdO8KMGX7XwOJimDBBuwVKvChpiMSMGVx4oZ8Q\nuGyZ7yhfujR0VCKekoZITB1yCDz9tN/oqW9f+I//8J3lIiGpT0MkC6xbBz/4AXz6qd/wqbAwdEQS\nUk71aZjZLWa2wswWm9kTZtYi0/cQyTcdOsCsWXDBBdC9O9xxh3YKlDAyXtMws77AS865UjO7CXDO\nuZ9V817VNERqaNUq3+fRtCncf79PKJJfcqqm4Zx70TlX9n+g14D2mb6HSD4rLISXX/b9HN26wV/+\nojWspP5E2qdhZs8AU5xzj1TzumoaInWwdCmMGQPHHOPXsGrVKnREUh9C1jQKavMhM5sNtK34FOCA\nCc656an3TABKqksYZSZNmvTVeSKRIJFI1CYkkbzUpYvf7OnnP4eTTvKd5L16hY5KMi2ZTJJMJkOH\nAURU0zCzscAPgd7OuWqnJqmmIZI5M2f6EVZjxsANN/i9yiU35VSfhpkNAH4KDN1XwhCRzCou9rsE\n/utffoTVypWhI5JcFMXkvjuA5sBsM1tkZndHcA8RqcLBB8O0aTBuHHznOzB5sjrJJbM0uU8kR/3r\nXzBqFBx1lO8k/8Y3QkckmZJTzVMiEg+dO/tO8sMP953kc+eGjkhygWoaInlg5kwYOxYuu8yPtGrY\nMHREUhchaxpKGiJ54v33/TIkDRrAww/7BRElO6l5SkQi981vwosv+t0Bu3aF2bNDRyTZSDUNkTz0\n0kt+PsdFF8GkSVBQq2m+Eoqap0Sk3m3e7BPHrl3wyCPQXqvEZQ01T4lIvWvTxm8tO3AgnHIKPPdc\n6IgkG6imISLMm+fndFxwAfzqV2quijs1T4lIcFu2+KSxezc8+ii0bfv1n5Ew1DwlIsEdfLBvrurR\nwzdXzZ8fOiKJI9U0RGQvzz3nV8ydMAGuvBIsyP9ppTpqnhKR2FmzBs45x+8UOHkyNG8eOiIpo+Yp\nEYmdI46AV17xyaKoCFasCB2RxIGShohUq0kTX8u45hro2ROmTg0dkYSm5ikRScuiRTBiBJx9Ntxy\ni4blhqQ+DRHJCh995OdzlJTAY49B69ahI8pP6tMQkazQqpUfWXXqqb6fY8mS0BFJfVPSEJEaadgQ\nbroJfvMb6NvX1zgkf6h5SkRqbfFiGD4czjsPfv1rbe5UX9SnISJZ64MPYORIaNTILz/SsmXoiHKf\n+jREJGu1bg2zZkGnTr6fY/ny0BFJlJQ0RKTOCgrg97+HX/4SEgl48snQEUlU1DwlIhm1cKHv5xg/\n3q9dpXWrMk99GiKSUzZsgGHD4Oij4d57/cxyyRz1aYhITjn0UJg7F0pLoVcv2LgxdESSKUoaIhKJ\nJk38aKpBg+Db3/bDcyX7qXlKRCI3dSpcfjn8+c9+7Sqpm5DNU1pyTEQiN3KkX2p9+HB46y249lp1\nkGerjNc0zOwGYBhQCmwCxjrnqmzRVE1DJL+sXw9Dh8Jxx/laR+PGoSPKTjk1esrMmjvnPkmdXwl0\nds5dWs17lTRE8szOnXDhhfD++/D0035vcqmZnBo9VZYwUprhaxwiIgA0beoXOUwk4PTTYdWq0BFJ\nTUTSp2FmNwLfB7YBvaK4h4hkrwYN/AKHRx7pdwT829/gjDNCRyXpqFXzlJnNBtpWfApwwATn3PQK\n77sWaOKcm1TNddzEiRO/epxIJEgkEjWOR0Sy16xZMHo03HYbfO97oaOJp2QySTKZ/Orx9ddfnzt9\nGntc3Oww4Hnn3AnVvK4+DRHhzTdhyBC45BK47jqNrPo6OdWnYWZHV3h4NrAi0/cQkdxywgnw6qu+\nmeqHP/TbyUo8RTF66nGgEN8Bvha4xDm3oZr3qqYhIl/55BM4/3z44gt4/HFo0SJ0RPGUU0Nua3Rz\nJQ0RqWT3brjqKpg3z+9HfthhoSOKn5xqnhIRqYuCArjrLj+X4/TTtWZV3KimISKx9fjjcNllfuHD\nPn1CRxMfqmmIiFRhxAifOEaNgilTQkcjoAULRSTmevaEF1/0S6xv2ABXXx06ovym5ikRyQrr1sGA\nATB4MNx8s59Vnq80ekpEJA0ffQRnneWXWb/vPmjUKHREYahPQ0QkDa1a+aaqHTv8DPIdO0JHlH+U\nNEQkqzRpAk884WsbiQRs2hQ6ovyipCEiWaegAP70J7+hU48e8PbboSPKHxo9JSJZyQwmToRDD/Uj\nrJ59Frp2DR1V7lNHuIhkvaeegvHj/ZyOnj1DRxM9dYSLiNTB8OF+1viIEb7GIdFR0hCRnNCnj08Y\nF18MDz8cOprcpT4NEckZRUXw97/7SYBbt8IVV4SOKPcoaYhITjnuOHj5ZejXzyeOX/xCOwFmkjrC\nRSQnbdwIxcXQqxf87ne5teyIlhEREYnAtm1+rapjjoHJk/38jlyg0VMiIhE46CCYNcvPGh8xAj77\nLHRE2U9JQ0RyWrNmMG0aNG7sFzv89NPQEWU3JQ0RyXmNGsEjj0C7djBwIGzfHjqi7KWkISJ5oWFD\nv5z6cceVj6ySmlPSEJG80aAB3H23X+Swd2/YsiV0RNlHSUNE8ooZ3HqrH1WVSPgtZCV9OTIATUQk\nfWZw441+b46ePf0s8g4dQkeVHZQ0RCRvTZjgR1edeabfEfCoo0JHFH9KGiKS137yE1/jSCRg9mz4\n1rdCRxRvShoikvfGj/eJo3dvmDEDTjwxdETxpaQhIgJ8//s+cfTvD88/D926hY4oniIbPWVm15hZ\nqZm1iuoeIiKZdO65cM89MGgQLFwYOpp4iqSmYWbtgX7A2iiuLyISlWHD/OiqwYP9pk6nnho6oniJ\nqqbxe+CnEV1bRCRSQ4f6VXEHD4YFC0JHEy8ZTxpmNhR41zn3ZqavLSJSX846yy87MmQIvP566Gji\no1b7aZjZbKBtxacAB/wC+DnQzzm3w8zWAKc45z6s5jraT0NEYu3552HsWL9S7umnh47GC7mfRq36\nNJxz/ap63syOBw4HlpiZAe2Bf5hZkXNuc1WfmTRp0lfniUSCRCJRm5BERCIxaBA88IDv63j6aeje\nvf5jSCaTJJPJ+r9xFSLduS9V0+jqnKtyPUnVNEQkW7zwgh+W+9RTfsHDkHJ55z6Hb7oSEclqAwbA\nQw/B8OEwb17oaMLRHuEiIjUwezaMGgVPPglnnBEmhlyuaYiI5JR+/eDRR+G734VXXgkdTf1T0hAR\nqaG+feHhh31TVb4Nx1XSEBGphf794f77/UTARYtCR1N/lDRERGpp8GD405/8sNylS0NHUz+0yq2I\nSB0MHw4lJVBc7HcA7Nw5dETRUtIQEamjkSPhiy98J/mcOVBYGDqi6ChpiIhkwOjRPnH07esTR65u\nHaukISKSIT/4gU8cffrA3LnQsWPoiDJPSUNEJIMuucQnjt69feJo3z50RJmlpCEikmFXXbVn4jj0\n0NARZY6ShohIBP793+Hzz8ubqg4+OHREmaGkISISkQkTYNcuPxx3zhw48MDQEdWdFiwUEYmQc/Dj\nH/tZ4zNnQrNmdb9myAULlTRERCJWWgrjxsH69TB9OjRuXLfrKWmIiOS43bvh/PN9Apk6FQrq0Dmg\npdFFRHJcQYFfGXfXLj+fo7Q0dES1o6QhIlJPGjeGJ56Ad96BK6/0/R3ZRklDRKQeNW0Kzz7r9+GY\nMCF0NDWnIbciIvWsRQt44QU480x/ft11oSNKn5KGiEgArVv7/cZ79vSJ47LLQkeUHiUNEZFAvvnN\n8sRxwAEwZkzoiL6ekoaISEBHHAGzZvl1qlq2hCFDQke0b+oIFxEJrFMnmDbND8WdNy90NPumpCEi\nEgNFRX4exznnxHu/cSUNEZGY6NcP7rgDBg2CNWtCR1M19WmIiMTIyJHwwQfQv79vqmrbNnREe1LS\nEBGJmcsugy1bYODA+C2prgULRURiyDm/1Mjy5TBjBuy/f/lrObVgoZlNNLP3zGxR6hiQ6XuIiOQ6\nM7j9dt88NWqUXyU3DqLqCP+dc65r6nghonvklGQyGTqE2FBZlFNZlMvHsmjQAB58ED75BC69NB4L\nHEaVNIJUm7JZPv6DqI7KopzKoly+lkWjRvDkk34YbhwWOIyqI/wKMxsDLASucc59HNF9RERyXvPm\n8NxzcMYZ0KZN2FhqlTTMbDZQcSCYAQ6YANwN3OCcc2Z2I/A7YFxdAxURyWetW/s9xr/znbBxRDp6\nysw6AtOdc12qeT0GLXQiItkn1OipjDdPmdkhzrmNqYffBZZV995QX1pERGonij6NW8zsJKAUeAcY\nH8E9REQkgKCT+0REJLukNeTWzAaY2VtmtsrMrq3mPbeb2WozW5yqaezzs2bW0sxmmdlKM5tpZgdW\neO1nqWutMLP+FZ7vamZLU9f6Q4XnG5nZlNRnXjWzDjUtiHRlQVlcbWbLU/eebWaHZb4U9v19Kr0n\nWFlUeP0cMys1s66Z+/Z73SP2ZWFmI1O/G2+a2UOZLYE97hPrsjCzw8zsJfOTjxeb2cDMl8K+v0+l\n99RHWdxoZuvMbHule9f8b6dzbp8HPrG8DXQE9gMWA9+q9J6BwHOp828Dr33dZ4Gbgf+XOr8WuCl1\n3hn4J77p7PDU58tqRK8Dp6bOnweKU+eXAnenzs8Dpnzd96rNkSVlcSawf+r8knwui9Tj5sBcYD7Q\nNV/LAjga+AfQIvW4dR6XxX8B41PnnYA1eVAWRfgRr9sr3b/GfzvTqWkUAaudc2udcyXAFGBYpfcM\nAx4EcM69DhxoZm2/5rPDgAdS5w8AZ6fOh6YC3+2cewdYDRSZ2SHAAc65N1Lve7DCZype63GgTxrf\nqzZiXxbOubnOuc9Sz78GtMvMV99L7Msi5VfATcDnGfjO1cmGsvghcJdzbnsqhg8y89X3kg1l4YAW\nqfODgPV1/9pVikVZpK69wDm3qYoYa/y3M52k0Q54t8Lj99j7D1F179nXZ9uWfQnnR1uVTVmp/Jn1\nFa71XjXX+uozzrkvgW1m1iqN71ZT2VAWFY0DZuzzG9Ve7Msi1RzV3jkXVRmUiX1ZAIXAsWY2z8zm\nm1lx2t+uZrKhLCYBY8zsXeBZ4Mr0vlqNxaUs0oox3b+dUc0Ir81Q2kz2yMdpKG+QsjCz0UA3fHNV\nXNRbWZiZAbcCF9bx/lGp79+LAnwTVU+gA/DfZnZ8Wc0jsPoui+8B9zvnfm9mpwEPAcfV4XqZFPu/\nnenUNNbjf8nKtGfv6tx64LAq3rOvz25MVcNIVSU3p3Gtqp7f4zNm1hDfbvtRGt+tprKhLDCzvsDP\ngLNSVdsoxL0sDgCOB5JmtgY4DZgWUWd43MsC/P9Un3HOlaaaLlYBx6T39WokG8piHDAVwDn3GrC/\nmbVO7+vVSFzKYl/eo6Z/O9PozGlIeYdMI3yHTKdK7xlEeWfOaZR35lT7WXxnzrX76MxpBBzBnp05\nr+Hb6AzfsTUg9fxllHfmnE90nb/ZUBYnp953VBRlkE1lUSmWOcDJ+VoWQDHwl9R5a2At0DLPyqKs\nI/w54MLUeSfgvVz/vahwvx2VHtf4b2e6X34AsBLfsXJd6rnxwI8qvOfOVJBLqDBKparPpp5vBbyY\nem0WcFCF136WutYKoH+F57sBb6audVuF5xvj/+ewOvWLcngUvwRZUhazgQ3AotQv0NP5WhaVYn2J\niEZPZUtZ4Jvrlqfuf26+lgU+UczD/yFeBPTJg7K4Gd93sRtYB/z/1PM1/tupyX0iIpK2qPbTEBGR\nHKSkISIiaVPSEBGRtClpiIhI2pQ0REQkbUoaIiKSNiUNERFJm5KGiIik7f8AfhZN+Vl+0qwAAAAA\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12745c450>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t=np.linspace(0,.00001,num=1000)\n",
    "plt.plot(t,np.exp(t)-1-t-t**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
